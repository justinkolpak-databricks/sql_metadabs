from databricks.bundles.jobs import Job, notebook_task, sql_notebook_task, task
import json
import pprint

# Open json metadata and deserialize to dict
with open('task_metadata.json') as f:
    task_list = json.load(f)

@sql_notebook_task(
    notebook_path='notebooks/bronze_ingest.sql', warehouse_id='475b94ddc7cd5211'
)
def ingestion_task(
    src_catalog: str,
    src_schema: str,
    src_table: str,
    tgt_catalog: str,
    tgt_schema: str,
    tgt_table: str,
):
    pass

def create_tasks(task_list):
    """Add task objects to task list

    Args:
        task_list (list): List of task metadata

    Returns:
        list: List of task metadata and objects
    """
    for t in task_list:
        t['task'] = ingestion_task(
            src_catalog=t['src_catalog'],
            src_schema=t['src_schema'],
            src_table=t['src_table'],
            tgt_catalog=t['tgt_catalog'],
            tgt_schema=t['tgt_schema'],
            tgt_table=t['tgt_table'],
        ).with_task_key(f'{t['src_catalog']}_{t['src_schema']}_{t['tgt_table']}')

    return task_list

def add_deps(task_list):
    """Add dependencies to task objects

    Args:
        task_list (list): List of task metadata and objects

    Returns:
        _type_: List of task metadata and objects with dependencies added
    """
    for t in task_list:
        if t['depends_on']:
            depends_on_task_names = t['depends_on']
            depends_on_tasks = [t['task'] for t in task_list if t['task_key'] in depends_on_task_names]
            for d in depends_on_tasks:
                t['task'] = t['task'].add_depends_on(d)
  
    return task_list

task_list_filtered = [t for t in task_list if t['batch'] in ('bronze_01', 'silver_01')]
task_list_w_obj = create_tasks(task_list_filtered)
task_list_w_deps = add_deps(task_list_w_obj)
task_obj_list = [t['task'] for t in task_list_w_obj]

job_with_autogenerated_tasks = Job.create(
   resource_name='sql_metadabs_ingest',
   name='sql_metadabs_ingest',
   tasks=task_obj_list # type: ignore
)