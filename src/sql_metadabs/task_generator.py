from databricks.bundles.jobs import Job, notebook_task

table_names = ['hr']

#@notebook_task(notebook_path="/Users/justin.kolpak/sql_metadabs/sql_metadabs/src/sql_metadabs/sql_notebook.sql")# , warehouse_id='475b94ddc7cd5211')
@notebook_task(notebook_path="/src/sql_metadabs/sql_notebook.sql")# , warehouse_id='475b94ddc7cd5211')
def ingestion_task(catalog_name: str, 
                schema_name: str,
                table_name:str,
                file_path: str,
                file_format: str,
                infer_schema: bool,
                headers_included: bool,
                line_sep: str,
                file_name_pattern: str,
                schema: str,                  
                ):
  pass

my_job_with_autogenerated_tasks = Job.create(
  resource_name = "ingestion_job",
  name = "Ingestion Job",
  tasks = [
    ingestion_task(catalog_name = 'justin_kolpak',
                    schema_name = 'tpch',
                    table_name = table_name,
                    file_path='/Volumes/tpcdi/tpcdi_raw_data/tpcdi_volume/sf=10/Batch1/',
                    file_format='csv',
                    infer_schema=False,
                    headers_included=False,
                    line_sep=",",
                    file_name_pattern="HR.csv",
                    schema="employeeid BIGINT COMMENT 'ID of employee', managerid BIGINT COMMENT 'ID of employeeâ€™s manager', employeefirstname STRING COMMENT 'First name', employeelastname STRING COMMENT 'Last name', employeemi STRING COMMENT 'Middle initial', employeejobcode STRING COMMENT 'Numeric job code', employeebranch STRING COMMENT 'Facility in which employee has office', employeeoffice STRING COMMENT 'Office number or description', employeephone STRING COMMENT 'Employee phone number'"
                    )
    .with_task_key('ingestion_test')
    .with_job_cluster_key("Default")
    for table_name in table_names
  ]
)